{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5819470, 3)\n"
     ]
    }
   ],
   "source": [
    "file=pd.read_csv('animals_comments.csv',index_col=None)\n",
    "print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creator_name    32050\n",
       "userid              0\n",
       "comment           488\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_saying=['cat','cats','bobcat','cheetah','cougar','jaguar','kitten','kitty','leopard','lion']\n",
    "dog_saying=['dog','dogs','canine', 'pup', 'puppy', 'cur', 'doggy', 'hound', 'mongrel', 'mutt', 'pooch', 'stray', 'tyke', 'bowwow', 'domestic', 'fido', 'flea bag', 'tail-wagger']\n",
    "saying=cat_saying+dog_saying+['pet','pets']\n",
    "def myFunction(comment):\n",
    "    try:\n",
    "        if 'my' in comment and any(word in comment for word in saying):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['label'] = file.apply (lambda row: myFunction(row[2]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_name</th>\n",
       "      <th>userid</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug The Pug</td>\n",
       "      <td>87</td>\n",
       "      <td>I shared this to my friends and mom the were lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug The Pug</td>\n",
       "      <td>87</td>\n",
       "      <td>Super cute  üòÄüêïüê∂</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bulletproof</td>\n",
       "      <td>530</td>\n",
       "      <td>stop saying get em youre literally dumb . have...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meu Zool√≥gico</td>\n",
       "      <td>670</td>\n",
       "      <td>Tenho uma jiboia e um largato</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ojatro</td>\n",
       "      <td>1031</td>\n",
       "      <td>I wanna see what happened to the pigs after th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tingle Triggers</td>\n",
       "      <td>1212</td>\n",
       "      <td>Well shit now Im hungry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hope For Paws - Official Rescue Channel</td>\n",
       "      <td>1806</td>\n",
       "      <td>when I saw the end it said to adopt  I saw dif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hope For Paws - Official Rescue Channel</td>\n",
       "      <td>2036</td>\n",
       "      <td>Holy crap. That is quite literally the most ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Life Story</td>\n",
       "      <td>2637</td>\n",
       "      <td>Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì„Åß„Åô„ÅãÔºü</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Brian Barczyk</td>\n",
       "      <td>2698</td>\n",
       "      <td>Call the teddy Larry</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Dodo</td>\n",
       "      <td>2702</td>\n",
       "      <td>üòêü§îüòìüò¢üò≠üò≠üò≠üò≠üòü</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hope For Paws - Official Rescue Channel</td>\n",
       "      <td>2911</td>\n",
       "      <td>That mother cat looks like my own Im guessing ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hope For Paws - Official Rescue Channel</td>\n",
       "      <td>2911</td>\n",
       "      <td>Its people like Hope For Paws who truly make t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Talking Kitty Cat</td>\n",
       "      <td>2911</td>\n",
       "      <td>steve: No wet food for a month!:cats immediate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brave Wilderness</td>\n",
       "      <td>3224</td>\n",
       "      <td>Dont call this a challenge because there will ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MaxluvsMya</td>\n",
       "      <td>3267</td>\n",
       "      <td>why are you always awake so late lol</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rise Up Society Fan Page</td>\n",
       "      <td>3372</td>\n",
       "      <td>Deb Tucker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Dodo</td>\n",
       "      <td>3466</td>\n",
       "      <td>Thats a deer isnt it?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Brave Wilderness</td>\n",
       "      <td>3466</td>\n",
       "      <td>there is no safe way to hold a crab. Somehow t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Brave Wilderness</td>\n",
       "      <td>3466</td>\n",
       "      <td>Red before yellow will kill a fellow...Some of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               creator_name  userid  \\\n",
       "0                              Doug The Pug      87   \n",
       "1                              Doug The Pug      87   \n",
       "2                               bulletproof     530   \n",
       "3                             Meu Zool√≥gico     670   \n",
       "4                                    ojatro    1031   \n",
       "5                           Tingle Triggers    1212   \n",
       "6   Hope For Paws - Official Rescue Channel    1806   \n",
       "7   Hope For Paws - Official Rescue Channel    2036   \n",
       "8                                Life Story    2637   \n",
       "9                             Brian Barczyk    2698   \n",
       "10                                 The Dodo    2702   \n",
       "11  Hope For Paws - Official Rescue Channel    2911   \n",
       "12  Hope For Paws - Official Rescue Channel    2911   \n",
       "13                        Talking Kitty Cat    2911   \n",
       "14                         Brave Wilderness    3224   \n",
       "15                               MaxluvsMya    3267   \n",
       "16                 Rise Up Society Fan Page    3372   \n",
       "17                                 The Dodo    3466   \n",
       "18                         Brave Wilderness    3466   \n",
       "19                         Brave Wilderness    3466   \n",
       "\n",
       "                                              comment  label  \n",
       "0    I shared this to my friends and mom the were lol      0  \n",
       "1                                     Super cute  üòÄüêïüê∂      0  \n",
       "2   stop saying get em youre literally dumb . have...      0  \n",
       "3                       Tenho uma jiboia e um largato      0  \n",
       "4   I wanna see what happened to the pigs after th...      0  \n",
       "5                             Well shit now Im hungry      0  \n",
       "6   when I saw the end it said to adopt  I saw dif...      0  \n",
       "7   Holy crap. That is quite literally the most ad...      0  \n",
       "8                               Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì„Åß„Åô„ÅãÔºü      0  \n",
       "9                                Call the teddy Larry      0  \n",
       "10                                          üòêü§îüòìüò¢üò≠üò≠üò≠üò≠üòü      0  \n",
       "11  That mother cat looks like my own Im guessing ...      1  \n",
       "12  Its people like Hope For Paws who truly make t...      0  \n",
       "13  steve: No wet food for a month!:cats immediate...      0  \n",
       "14  Dont call this a challenge because there will ...      0  \n",
       "15               why are you always awake so late lol      0  \n",
       "16                                         Deb Tucker      0  \n",
       "17                              Thats a deer isnt it?      0  \n",
       "18  there is no safe way to hold a crab. Somehow t...      0  \n",
       "19  Red before yellow will kill a fellow...Some of...      0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rid_of_nulls(value):\n",
    "    if pd.isnull(value):\n",
    "        return 'null'\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "file['creator_name']=file['creator_name'].apply(get_rid_of_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=file.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creator_name    0\n",
       "userid          0\n",
       "comment         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5786942, 3)\n"
     ]
    }
   ],
   "source": [
    "print(file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator_name</th>\n",
       "      <th>userid</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doug The Pug</td>\n",
       "      <td>87</td>\n",
       "      <td>I shared this to my friends and mom the were lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doug The Pug</td>\n",
       "      <td>87</td>\n",
       "      <td>Super cute  üòÄüêïüê∂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bulletproof</td>\n",
       "      <td>530</td>\n",
       "      <td>stop saying get em youre literally dumb . have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meu Zool√≥gico</td>\n",
       "      <td>670</td>\n",
       "      <td>Tenho uma jiboia e um largato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ojatro</td>\n",
       "      <td>1031</td>\n",
       "      <td>I wanna see what happened to the pigs after th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    creator_name  userid                                            comment\n",
       "0   Doug The Pug      87   I shared this to my friends and mom the were lol\n",
       "1   Doug The Pug      87                                    Super cute  üòÄüêïüê∂\n",
       "2    bulletproof     530  stop saying get em youre literally dumb . have...\n",
       "3  Meu Zool√≥gico     670                      Tenho uma jiboia e um largato\n",
       "4         ojatro    1031  I wanna see what happened to the pigs after th..."
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.to_csv('clean_animals_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error line 1: <class '_csv.Error'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('clean_animals_comments.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    linenumber = 1\n",
    "    try:\n",
    "        for row in reader:\n",
    "            linenumber += 1\n",
    "    except Exception as e:\n",
    "        print ((\"Error line %d: %s\" % (linenumber, str(type(e)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=pd.read_csv('clean_animals_comments.csv')\n",
    "print(sample.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "sc =SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|        creator_name|userid|             comment|\n",
      "+--------------------+------+--------------------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|\n",
      "|         bulletproof| 530.0|stop saying get e...|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|\n",
      "|              ojatro|1031.0|I wanna see what ...|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|\n",
      "+--------------------+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.load('animals_comments.csv', format='com.databricks.spark.csv', header='true', inferSchema='true')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5820035"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------------------+\n",
      "| creator_name|userid|             comment|\n",
      "+-------------+------+--------------------+\n",
      "| Doug The Pug|  87.0|I shared this to ...|\n",
      "| Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|\n",
      "|  bulletproof| 530.0|stop saying get e...|\n",
      "|Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|\n",
      "|       ojatro|1031.0|I wanna see what ...|\n",
      "+-------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.dropna(thresh=3,subset=('creator_name','userid','comment'))\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5786944"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o52.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 42, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/macbookair/Platforms/spark/2.1.1/python/lib/pyspark.zip/pyspark/worker.py\", line 125, in main\n    (\"%d.%d\" % sys.version_info[:2], version))\nException: Python in worker has different version 3.5 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2386)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2385)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2392)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2128)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2127)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2818)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2127)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2342)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:248)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/macbookair/Platforms/spark/2.1.1/python/lib/pyspark.zip/pyspark/worker.py\", line 125, in main\n    (\"%d.%d\" % sys.version_info[:2], version))\nException: Python in worker has different version 3.5 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d49f4c445485>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mfunc_udf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooleanType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog_cat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Platforms/spark/2.1.1/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Platforms/spark/2.1.1/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Platforms/spark/2.1.1/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Platforms/spark/2.1.1/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o52.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 42, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/macbookair/Platforms/spark/2.1.1/python/lib/pyspark.zip/pyspark/worker.py\", line 125, in main\n    (\"%d.%d\" % sys.version_info[:2], version))\nException: Python in worker has different version 3.5 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1925)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1951)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:333)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2386)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:57)\n\tat org.apache.spark.sql.Dataset.withNewExecutionId(Dataset.scala:2788)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$execute$1(Dataset.scala:2385)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collect(Dataset.scala:2392)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2128)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2127)\n\tat org.apache.spark.sql.Dataset.withTypedCallback(Dataset.scala:2818)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2127)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2342)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:248)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/macbookair/Platforms/spark/2.1.1/python/lib/pyspark.zip/pyspark/worker.py\", line 125, in main\n    (\"%d.%d\" % sys.version_info[:2], version))\nException: Python in worker has different version 3.5 than that in driver 3.6, PySpark cannot run with different minor versions.Please check environment variables PYSPARK_PYTHON and PYSPARK_DRIVER_PYTHON are correctly set.\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:144)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec$$anonfun$doExecute$1.apply(BatchEvalPythonExec.scala:87)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:99)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:322)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf,col\n",
    "\n",
    "cat_saying=['cat','cats','bobcat','cheetah','cougar','jaguar','kitten','kitty','leopard','lion']\n",
    "dog_saying=['dog','dogs','canine', 'pup', 'puppy', 'cur', 'doggy', 'hound', 'mongrel', 'mutt', 'pooch', 'stray', 'tyke', 'bowwow', 'domestic', 'fido', 'flea bag', 'tail-wagger']\n",
    "saying=cat_saying+dog_saying+['pet','pets']\n",
    "def myFunction(comment):\n",
    "    try:\n",
    "        if 'my' in comment and any(word in comment for word in saying):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "func_udf = udf(myFunction, BooleanType())\n",
    "df2 = df_clean.withColumn('dog_cat',func_udf(df_clean['text']))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------------------+-------+--------------------+-----------------+\n",
      "| creator_name|userid|             comment|dog_cat|                text|             name|\n",
      "+-------------+------+--------------------+-------+--------------------+-----------------+\n",
      "| Doug The Pug|  87.0|I shared this to ...|  false|[i, shared, this,...| [doug, the, pug]|\n",
      "| Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|       [super, cute]| [doug, the, pug]|\n",
      "|  bulletproof| 530.0|stop saying get e...|  false|[stop, saying, ge...|    [bulletproof]|\n",
      "|Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|[tenho, uma, jibo...|[meu, zool, gico]|\n",
      "|       ojatro|1031.0|I wanna see what ...|  false|[i, wanna, see, w...|         [ojatro]|\n",
      "+-------------+------+--------------------+-------+--------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+\n",
      "|        creator_name|userid|             comment|dog_cat|\n",
      "+--------------------+------+--------------------+-------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|  false|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|\n",
      "|         bulletproof| 530.0|stop saying get e...|  false|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|\n",
      "|              ojatro|1031.0|I wanna see what ...|  false|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|  false|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|  false|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|  false|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|  false|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|  false|\n",
      "|            The Dodo|2702.0|  üòêü§îüòìüò¢üò≠üò≠üò≠üò≠üòü|  false|\n",
      "|Hope For Paws - O...|2911.0|That mother cat l...|  false|\n",
      "|Hope For Paws - O...|2911.0|Its people like H...|  false|\n",
      "|   Talking Kitty Cat|2911.0|steve: No wet foo...|  false|\n",
      "|    Brave Wilderness|3224.0|Dont call this a ...|  false|\n",
      "|          MaxluvsMya|3267.0|why are you alway...|  false|\n",
      "|Rise Up Society F...|3372.0|          Deb Tucker|  false|\n",
      "|            The Dodo|3466.0|Thats a deer isnt...|  false|\n",
      "|    Brave Wilderness|3466.0|there is no safe ...|  false|\n",
      "|    Brave Wilderness|3466.0|Red before yellow...|  false|\n",
      "+--------------------+------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond = (df[\"comment\"].like(\"%my dog%\") | df[\"comment\"].like(\"%I have a dog%\")\\\n",
    "        | df[\"comment\"].like(\"%my cat%\") | df[\"comment\"].like(\"%I have a cat%\"))\n",
    "\n",
    "df_clean = df.withColumn('dog_cat',cond)\n",
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, RegexTokenizer, CountVectorizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+--------------------+\n",
      "|        creator_name|userid|             comment|dog_cat|                name|\n",
      "+--------------------+------+--------------------+-------+--------------------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|  false|    [doug, the, pug]|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|    [doug, the, pug]|\n",
      "|         bulletproof| 530.0|stop saying get e...|  false|       [bulletproof]|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|   [meu, zool, gico]|\n",
      "|              ojatro|1031.0|I wanna see what ...|  false|            [ojatro]|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|  false|  [tingle, triggers]|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|  false|[hope, for, paws,...|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|  false|[hope, for, paws,...|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|  false|       [life, story]|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|  false|    [brian, barczyk]|\n",
      "+--------------------+------+--------------------+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"creator_name\", outputCol=\"name\", pattern=\"\\\\W\")\n",
    "df_clean = regexTokenizer.transform(df_clean)\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+--------------------+--------------------+\n",
      "|        creator_name|userid|             comment|dog_cat|                name|             rawName|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|  false|    [doug, the, pug]|(10000,[5710,5885...|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|    [doug, the, pug]|(10000,[5710,5885...|\n",
      "|         bulletproof| 530.0|stop saying get e...|  false|       [bulletproof]|(10000,[8647],[1.0])|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|   [meu, zool, gico]|(10000,[2564,3283...|\n",
      "|              ojatro|1031.0|I wanna see what ...|  false|            [ojatro]|(10000,[8067],[1.0])|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|  false|  [tingle, triggers]|(10000,[4532,5257...|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|  false|[hope, for, paws,...|(10000,[1036,3951...|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|  false|[hope, for, paws,...|(10000,[1036,3951...|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|  false|       [life, story]|(10000,[3477,6657...|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|  false|    [brian, barczyk]|(10000,[616,2123]...|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"name\", outputCol=\"rawName\", numFeatures=10000)\n",
    "df_clean = hashingTF.transform(df_clean)\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "|        creator_name|userid|             comment|dog_cat|                name|             rawName|                text|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|  false|    [doug, the, pug]|(10000,[5710,5885...|[i, shared, this,...|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|    [doug, the, pug]|(10000,[5710,5885...|       [super, cute]|\n",
      "|         bulletproof| 530.0|stop saying get e...|  false|       [bulletproof]|(10000,[8647],[1.0])|[stop, saying, ge...|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|   [meu, zool, gico]|(10000,[2564,3283...|[tenho, uma, jibo...|\n",
      "|              ojatro|1031.0|I wanna see what ...|  false|            [ojatro]|(10000,[8067],[1.0])|[i, wanna, see, w...|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|  false|  [tingle, triggers]|(10000,[4532,5257...|[well, shit, now,...|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|  false|[hope, for, paws,...|(10000,[1036,3951...|[when, i, saw, th...|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|  false|[hope, for, paws,...|(10000,[1036,3951...|[holy, crap, that...|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|  false|       [life, story]|(10000,[3477,6657...|                  []|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|  false|    [brian, barczyk]|(10000,[616,2123]...|[call, the, teddy...|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"comment\", outputCol=\"text\", pattern=\"\\\\W\")\n",
    "df_clean = regexTokenizer.transform(df_clean)\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        creator_name|userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        Doug The Pug|  87.0|I shared this to ...|  false|    [doug, the, pug]|(10000,[5710,5885...|[i, shared, this,...|(10000,[2293,4442...|\n",
      "|        Doug The Pug|  87.0|  Super cute  üòÄüêïüê∂|  false|    [doug, the, pug]|(10000,[5710,5885...|       [super, cute]|(10000,[349,2659]...|\n",
      "|         bulletproof| 530.0|stop saying get e...|  false|       [bulletproof]|(10000,[8647],[1.0])|[stop, saying, ge...|(10000,[639,796,8...|\n",
      "|       Meu Zool√≥gico| 670.0|Tenho uma jiboia ...|  false|   [meu, zool, gico]|(10000,[2564,3283...|[tenho, uma, jibo...|(10000,[422,1878,...|\n",
      "|              ojatro|1031.0|I wanna see what ...|  false|            [ojatro]|(10000,[8067],[1.0])|[i, wanna, see, w...|(10000,[2055,2077...|\n",
      "|     Tingle Triggers|1212.0|Well shit now Im ...|  false|  [tingle, triggers]|(10000,[4532,5257...|[well, shit, now,...|(10000,[157,2098,...|\n",
      "|Hope For Paws - O...|1806.0|when I saw the en...|  false|[hope, for, paws,...|(10000,[1036,3951...|[when, i, saw, th...|(10000,[349,437,1...|\n",
      "|Hope For Paws - O...|2036.0|Holy crap. That i...|  false|[hope, for, paws,...|(10000,[1036,3951...|[holy, crap, that...|(10000,[817,1339,...|\n",
      "|          Life Story|2637.0|Ê≠¶Âô®„ÅØ„ÇØ„Ç®„Çπ„Éà„ÅßË≤∞„Åà„Çã„Çì„Åò„ÇÉ„Å™„ÅÑ„Çì...|  false|       [life, story]|(10000,[3477,6657...|                  []|       (10000,[],[])|\n",
      "|       Brian Barczyk|2698.0|Call the teddy Larry|  false|    [brian, barczyk]|(10000,[616,2123]...|[call, the, teddy...|(10000,[2769,2816...|\n",
      "+--------------------+------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"text\", outputCol=\"rawComment\", numFeatures=10000)\n",
    "df_clean = hashingTF.transform(df_clean)\n",
    "df_clean.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 3471658\n",
      "Test Dataset Count: 2315286\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = df2.randomSplit([0.6, 0.4], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+-------+\n",
      "|        creator_name|  userid|             comment|dog_cat|\n",
      "+--------------------+--------+--------------------+-------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 66527.0|Shout out from Ca...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 70385.0|Billy just showed...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 80582.0|             Snapped|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 96010.0|Billi Takin Over ...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 96010.0|Subscribe for new...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 96010.0|Thumbs Up If You ...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...| 96010.0|Who rockin with t...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|144198.0|Lmfao oml folks d...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|179865.0|This the real ban...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|185783.0|         okay okay!!|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|252737.0|      this goes hard|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|254431.0|Billy a beast... ...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|254431.0|How u Wuga World ...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|264026.0|           AZ reppin|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|284283.0|They snapped üî•üî•...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|307368.0|Thats The Future ...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|307368.0|      ohh guuuurl !!|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|307368.0|ridin foreign wit...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|336823.0|              Sveeet|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|366751.0|Look i got this l...|  false|\n",
      "+--------------------+--------+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond = (df[\"comment\"].like(\"%my dog%\") | df[\"comment\"].like(\"%I have a dog%\")\\\n",
    "        | df[\"comment\"].like(\"%my cat%\") | df[\"comment\"].like(\"%I have a cat%\"))\n",
    "\n",
    "trainingData_clean = trainingData.withColumn('dog_cat',cond)\n",
    "trainingData_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer_name = RegexTokenizer(inputCol=\"creator_name\", outputCol=\"name\", pattern=\"\\\\W\")\n",
    "hashingTF_name = HashingTF(inputCol=\"name\", outputCol=\"rawName\", numFeatures=10000)\n",
    "regexTokenizer_comment = RegexTokenizer(inputCol=\"comment\", outputCol=\"text\", pattern=\"\\\\W\")\n",
    "hashingTF_comment = HashingTF(inputCol=\"text\", outputCol=\"rawComment\", numFeatures=10000)\n",
    "pipeline = Pipeline(stages=[regexTokenizer_name,hashingTF_name,regexTokenizer_comment,hashingTF_comment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|66527.0|Shout out from Ca...|  false|[cameralord, kor,...|(10000,[3203,7884...|[shout, out, from...|(10000,[128,2495,...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|70385.0|Billy just showed...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, just, sho...|(10000,[307,368,1...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|80582.0|             Snapped|  false|[cameralord, kor,...|(10000,[3203,7884...|           [snapped]|(10000,[3350],[1.0])|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi Takin Over ...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, takin, ov...|(10000,[1564,4233...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Subscribe for new...|  false|[cameralord, kor,...|(10000,[3203,7884...|[subscribe, for, ...|(10000,[1036,2861...|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(trainingData_clean)\n",
    "trainingDataset = pipelineFit.transform(trainingData_clean)\n",
    "trainingDataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+\n",
      "|        creator_name| userid|             comment|dog_cat|\n",
      "+--------------------+-------+--------------------+-------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|41444.0|                üíØüíØ|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|93552.0|BOONK GANGü§òü§òü§ò?...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|94581.0|I really like thi...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi slay him or...|  false|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billy and Swagg t...|  false|\n",
      "+--------------------+-------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cond = (df[\"comment\"].like(\"%my dog%\") | df[\"comment\"].like(\"%I have a dog%\")\\\n",
    "        | df[\"comment\"].like(\"%my cat%\") | df[\"comment\"].like(\"%I have a cat%\"))\n",
    "\n",
    "testData_clean = testData.withColumn('dog_cat',cond)\n",
    "testData_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|41444.0|                üíØüíØ|  false|[cameralord, kor,...|(10000,[3203,7884...|                  []|       (10000,[],[])|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|93552.0|BOONK GANGü§òü§òü§ò?...|  false|[cameralord, kor,...|(10000,[3203,7884...|       [boonk, gang]|(10000,[1883,8535...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|94581.0|I really like thi...|  false|[cameralord, kor,...|(10000,[3203,7884...|[i, really, like,...|(10000,[1310,3330...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi slay him or...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, slay, him...|(10000,[1187,4491...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billy and Swagg t...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, and, swag...|(10000,[1187,2427...|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelineFit = pipeline.fit(testData_clean)\n",
    "testDataset = pipelineFit.transform(testData_clean)\n",
    "testDataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|            features|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|66527.0|Shout out from Ca...|  false|[cameralord, kor,...|(10000,[3203,7884...|[shout, out, from...|(10000,[128,2495,...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|70385.0|Billy just showed...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, just, sho...|(10000,[307,368,1...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|80582.0|             Snapped|  false|[cameralord, kor,...|(10000,[3203,7884...|           [snapped]|(10000,[3350],[1.0])|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi Takin Over ...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, takin, ov...|(10000,[1564,4233...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Subscribe for new...|  false|[cameralord, kor,...|(10000,[3203,7884...|[subscribe, for, ...|(10000,[1036,2861...|(20000,[3203,7884...|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['rawName', 'rawComment'],outputCol='features')\n",
    "\n",
    "training = assembler.transform(trainingDataset)\n",
    "training.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|            features|label|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|66527.0|Shout out from Ca...|  false|[cameralord, kor,...|(10000,[3203,7884...|[shout, out, from...|(10000,[128,2495,...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|70385.0|Billy just showed...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, just, sho...|(10000,[307,368,1...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|80582.0|             Snapped|  false|[cameralord, kor,...|(10000,[3203,7884...|           [snapped]|(10000,[3350],[1.0])|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi Takin Over ...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, takin, ov...|(10000,[1564,4233...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Subscribe for new...|  false|[cameralord, kor,...|(10000,[3203,7884...|[subscribe, for, ...|(10000,[1036,2861...|(20000,[3203,7884...|    0|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "train=training.withColumn(\"label\", training['dog_cat'].cast(IntegerType()))\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|            features|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|41444.0|                üíØüíØ|  false|[cameralord, kor,...|(10000,[3203,7884...|                  []|       (10000,[],[])|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|93552.0|BOONK GANGü§òü§òü§ò?...|  false|[cameralord, kor,...|(10000,[3203,7884...|       [boonk, gang]|(10000,[1883,8535...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|94581.0|I really like thi...|  false|[cameralord, kor,...|(10000,[3203,7884...|[i, really, like,...|(10000,[1310,3330...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi slay him or...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, slay, him...|(10000,[1187,4491...|(20000,[3203,7884...|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billy and Swagg t...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, and, swag...|(10000,[1187,2427...|(20000,[3203,7884...|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = assembler.transform(testDataset)\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|            features|label|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|41444.0|                üíØüíØ|  false|[cameralord, kor,...|(10000,[3203,7884...|                  []|       (10000,[],[])|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|93552.0|BOONK GANGü§òü§òü§ò?...|  false|[cameralord, kor,...|(10000,[3203,7884...|       [boonk, gang]|(10000,[1883,8535...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|94581.0|I really like thi...|  false|[cameralord, kor,...|(10000,[3203,7884...|[i, really, like,...|(10000,[1310,3330...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi slay him or...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, slay, him...|(10000,[1187,4491...|(20000,[3203,7884...|    0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billy and Swagg t...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, and, swag...|(10000,[1187,2427...|(20000,[3203,7884...|    0|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing=test.withColumn(\"label\", test['dog_cat'].cast(IntegerType()))\n",
    "testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='features', labelCol='label',maxIter=10, regParam=0.01, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|        creator_name| userid|             comment|dog_cat|                name|             rawName|                text|          rawComment|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|41444.0|                üíØüíØ|  false|[cameralord, kor,...|(10000,[3203,7884...|                  []|       (10000,[],[])|(20000,[3203,7884...|    0|[5.34396707301585...|[0.99524582729688...|       0.0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|93552.0|BOONK GANGü§òü§òü§ò?...|  false|[cameralord, kor,...|(10000,[3203,7884...|       [boonk, gang]|(10000,[1883,8535...|(20000,[3203,7884...|    0|[5.34396707301585...|[0.99524582729688...|       0.0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|94581.0|I really like thi...|  false|[cameralord, kor,...|(10000,[3203,7884...|[i, really, like,...|(10000,[1310,3330...|(20000,[3203,7884...|    0|[5.34396707301585...|[0.99524582729688...|       0.0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billi slay him or...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billi, slay, him...|(10000,[1187,4491...|(20000,[3203,7884...|    0|[5.34396707301585...|[0.99524582729688...|       0.0|\n",
      "|#CameraLord‚Ñ¢ ‚Ä¢ Ko...|96010.0|Billy and Swagg t...|  false|[cameralord, kor,...|(10000,[3203,7884...|[billy, and, swag...|(10000,[1187,2427...|(20000,[3203,7884...|    0|[5.34396707301585...|[0.99524582729688...|       0.0|\n",
      "+--------------------+-------+--------------------+-------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = lrModel.transform(testing)\n",
    "prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.081\n",
      "MSE: 0.007\n",
      "MAE: 0.007\n",
      "r2: -0.027\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "eval = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = eval.evaluate(prediction)\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = eval.evaluate(prediction, {eval.metricName: \"mse\"})\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = eval.evaluate(prediction, {eval.metricName: \"mae\"})\n",
    "print(\"MAE: %.3f\" % mae)\n",
    "\n",
    "# r2 - coefficient of determination\n",
    "r2 = eval.evaluate(prediction, {eval.metricName: \"r2\"})\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
